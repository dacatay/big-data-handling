{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Intro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Daten > RAM für Python von Jascha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Daten > RAM für R von Niklas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Spark und Hadoop von Niklas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datahandling mit großen Datenmengen: Einleitung\n",
    "\n",
    "## Warum gibt es diese riesigen Datenmengen?\n",
    "\n",
    "***\"Die gleiche Menge an Daten, die in der gesamten Geschichte der Menschheit bis zum Jahr 2003 erzeugt wurde, fällt heute innerhalb von sieben Minuten an.\"***  Prof. Dr. Florian Heiß, Heinrich-Heine-Universität Düsseldorf\n",
    "\n",
    "\n",
    "***\"Bis 2020 gibt es 50 Milliarden vernetzte Geräte.\"***  Bernd Heinrichs, Cisco \n",
    "\n",
    "\n",
    "![geräte](Geraete3.png)\n",
    "\n",
    "## Warum wird das alles gespeichert?\n",
    "### Die langfristige Entwicklung\n",
    "**Der Preis für IBM Festplattenspeicher war 1956 34.000.000.000% höher als 2002.** \n",
    "### Und in den letzten Jahren?\n",
    "![preisgrafik](Entwicklung_Preis2.jpg)\n",
    "\n",
    "#### Zwischenfazit: Aufgrund des Preisverfalls ist es kaum noch mit Kosten verbunden Daten zu speichern!\n",
    "\n",
    "## Wo haben wir damit zu tun?\n",
    "\n",
    "Aktuell tritt das Problem insbesondere bei SAP-Tabellen auf.<br>Es ist aufgrund der globalen Gesamtentwicklung aber zu erwarten, dass wir immer häufiger mit immer größeren Datenmengen arbeiten werden.\n",
    "\n",
    "## Ab wann bekommen wir Probleme mit einem Datensatz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\dejdahl3\\Documents\\CSV\\TrainingSets\\Titani_Training.csv')\n",
    "\n",
    "import os \n",
    "filesize = os.path.getsize(r'C:\\Users\\dejdahl3\\Documents\\CSV\\TrainingSets\\Titani_Training.csv')\n",
    "\n",
    "import sys\n",
    "objectsize = sys.getsizeof(df)\n",
    "\n",
    "print('Größe der Datei: ', filesize)\n",
    "print('Größe des Objekts im Speicher: ', objectsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Objekt in Python ist deutlich Größer als die CSV-Datei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "print('Auslastung des Arbeitsspeichers:')\n",
    "print(psutil.virtual_memory())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unter normalen Umständen ist der Arbeitsspeicher nicht zu 100% frei.<br>\n",
    "\n",
    "** Zwischenfazit: Dateien können kleiner als der verfügbare Arbeitsspeicher seien und trotzdem zu groß für den Arbeitsspeicher!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wieso ist das Objekt in Python jetzt so groß?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beispiel: Eine 100MB CSV Datei mit 200k Reihen, 25 Spalten mit je 20 ASCII Zeichen gefüllt\n",
    "- jetzt muss jede Spalte und jede Reihe mit einem Header 48-byte Header getrennt werden getrennt werden im DataFrame\n",
    "200.000x25x48 = 240.000.000 Bit\n",
    "jetzt noch für alle 200.000 Reihen einen Index anlegen...\n",
    "\n",
    "<a href='http://stupidpythonideas.blogspot.co.uk/2014/09/why-does-my-100mb-file-take-2gb-of.html'> Beispiel Rechnung ganz ausgeführt</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was bezeichnen wir jetzt in diesem Fall als Daten größer als der Arbeitsspeicher?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Datensets die groß genug sind um den Arbeitsspeicher zum Überlaufen zu bringen, aber kleiner als 50 GB sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warum gibt es überhaupt einen Arbeitsspeicher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<img src='ramdisk-charts.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Der Arbeitsspeicher ist in Lese und Schreiboperationen dem alten Festplattenspeicher und den neuen SSDs deutlich Überlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<img src='Computer1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Die CPU ist über Hierarchien mit den verschiedenen Speichern verbunden. Zuerst kommt der Cache mit der schnellsten Zugriffszeit. Der Arbeitsspeicher ist hinter dem Cache angebracht. Hinter dem Arbeitsspeicher ist die Festplatte in der Hierarchie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<img src='solving-the-io-bottleneck-8-728.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Während die Rechenleistung in den letzten Jahren stark angestiegen ist, konnten die Input Output Zeiten von Festplatten mit der Entwicklung nicht mithalten. Das neue Problem ist nicht mehr die Rechenleitung sondern die Zugriffszeiten auf die Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lösung des Problemes sollen In-Memory-Datenbank Lösungen wie SAP HANA liefern"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
