{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Suche Ergebnisse zum Thema Larger than RAM Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Häufigsten Vorschläge:\n",
    "    1. PySpark\n",
    "    2. Pandas und schrittweise Dateneinlesen\n",
    "    3. Dask\n",
    "    4. PyTables\n",
    "    5. Blaze\n",
    "    6. Datenbanken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie Sinnvoll sind die Ansätze?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark:\n",
    "    + Ausgelegt für große Cluster \n",
    "    - Ausgelegt für wirklich große Daten im Terrabyte bereich und der Funktion auf verteilten Rechensystemen\n",
    "Auch wenn es immer wieder Menschen gibt die PySpark auf einem PC/Laptop nutzen, wir tuen es nicht. Spark ist für Datenmengen im Terrabyte Bereich gemacht. Es funktioniert auf dem PC, aber erst mit ein paar veränderten Einstellungen und es gibt Packages die jenes auf einem PC effektiver und einfacher erledigen können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas und schrittweise Dateneinlesen:\n",
    "    + Die wahrscheinlich einfachste Lösung da nahezu jeder mit dem Pandas Dataframe umgehen kann\n",
    "    - Was tun bei Aufgaben wie joins ... wo mehr als nur ein einfaches itterieren benötigt wird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask:\n",
    "    + intuitives Pandas DataFrame Verhalten und gute API\n",
    "    - Speichert alle Daten nachher in mehreren Partitionen, daher hat man die Daten nachher mehrfach im System liegen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTables:\n",
    "    + gibt gute Videos und eine gut Beschriebene API\n",
    "    - HDF5 und der Aufbau nicht intuitiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blaze:\n",
    "    + gute API und Videos zum Thema\n",
    "    - kein klassisches Package um große Datenmengen zu bearbeiten, eher um verschiedene Datenformate/speicher mit der selben Abfrage zu bearbeiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datenbanken:\n",
    "    + können auch ausserhalb gehostet werden und gibt es in vielen verschiedenen Formaten und Arten(NoSQL, SQL, ACID, Verfügbareit vs Konsistenz vs Funktion)\n",
    "    - Datensicherheit und Zugriff wenn nicht im EY-System, für seltene Larger Than RAM Fälle zu umständlich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf Youtube findet man noch Videos zu anderen Packages. Meistens werden sie euphorisch von ihrem Erfinder vorgestellt, sind schon 5 Jahre alte und sind in Internetforen zu recht kaum bekannt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
